<!DOCTYPE html>
<html lang="en" data-theme="dark">
<head>
    <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-MBJVZS7Z');</script>
    <!-- End Google Tag Manager -->

    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Learn production-tested patterns for context engineering in AI agents. Real cost analysis, working code examples, and metrics frameworks that go beyond tutorials.">
    <title>Context Engineering for AI Agents: Managing the Finite Resource That Determines Success | Fenlo AI</title>

    <!-- Security Headers -->
    <meta http-equiv="X-Content-Type-Options" content="nosniff">
    <meta http-equiv="X-Frame-Options" content="SAMEORIGIN">
    <meta http-equiv="X-XSS-Protection" content="1; mode=block">
    <meta name="referrer" content="strict-origin-when-cross-origin">

    <!-- SEO -->
    <meta name="author" content="Fenlo AI">
    <meta name="robots" content="index, follow">
    <link rel="canonical" href="https://fenloai.com/pages/blog/context-engineering/">

    <!-- Favicon -->
    <link rel="icon" type="image/svg+xml" href="../../../assets/fenloai-icon.svg">

    <!-- Preload Font -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Outfit:wght@300;400;500;600;700;800&display=swap" rel="stylesheet">

    <!-- Open Graph -->
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://fenloai.com/pages/blog/context-engineering.html">
    <meta property="og:title" content="Context Engineering for AI Agents: Managing the Finite Resource That Determines Success">
    <meta property="og:description" content="Learn production-tested patterns for context engineering in AI agents. Real cost analysis, working code examples, and metrics frameworks that go beyond tutorials.">

    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Context Engineering for AI Agents: Managing the Finite Resource That Determines Success">
    <meta name="twitter:description" content="Learn production-tested patterns for context engineering in AI agents. Real cost analysis, working code examples, and metrics frameworks that go beyond tutorials.">

    <!-- Main Stylesheet -->
    <link rel="stylesheet" href="../../../css/styles.css">

    <!-- Blog-specific styles -->
    <style>
        /* Reading Progress Bar */
        .reading-progress {
            position: fixed;
            top: 0;
            left: 0;
            width: 0%;
            height: 3px;
            background: linear-gradient(90deg, var(--accent-primary), var(--accent-primary-light));
            z-index: 9999;
            transition: width 0.1s ease-out;
        }

        /* Blog Hero */
        .blog-hero {
            padding: var(--space-2xl) var(--container-padding) var(--space-xl);
            max-width: 800px;
            margin: 0 auto;
            position: relative;
        }

        .article-meta {
            display: flex;
            align-items: center;
            gap: 1rem;
            margin-bottom: var(--space-md);
            font-size: 0.9rem;
            color: var(--text-muted);
        }

        .category-tag {
            background: linear-gradient(135deg, var(--accent-primary), var(--accent-primary-light));
            color: white;
            padding: 0.35rem 1rem;
            border-radius: 20px;
            font-size: 0.8rem;
            font-weight: 500;
            letter-spacing: 0.3px;
        }

        .reading-time {
            display: flex;
            align-items: center;
            gap: 0.4rem;
        }

        .reading-time svg {
            width: 16px;
            height: 16px;
            opacity: 0.6;
        }

        .blog-hero h1 {
            font-size: clamp(2rem, 4vw, 2.75rem);
            font-weight: 700;
            line-height: 1.15;
            margin-bottom: var(--space-md);
            letter-spacing: -0.5px;
        }

        .article-intro {
            font-size: 1.2rem;
            color: var(--text-secondary);
            line-height: 1.8;
        }

        .author-byline {
            display: flex;
            align-items: center;
            gap: 0.75rem;
            margin-top: var(--space-md);
            padding-top: var(--space-md);
            border-top: 1px solid var(--glass-border);
        }

        .author-avatar {
            width: 44px;
            height: 44px;
            background: linear-gradient(135deg, var(--accent-primary), var(--accent-primary-light));
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
            font-weight: 700;
            font-size: 1rem;
        }

        .author-info {
            display: flex;
            flex-direction: column;
        }

        .author-name {
            font-weight: 600;
            font-size: 0.95rem;
            color: var(--text-primary);
        }

        .author-role {
            font-size: 0.85rem;
            color: var(--text-muted);
        }

        .publish-date {
            margin-left: auto;
            font-size: 0.85rem;
            color: var(--text-muted);
        }

        /* Article Container */
        .article-container {
            max-width: 760px;
            margin: 0 auto;
            padding: 0 var(--container-padding) var(--space-3xl);
        }

        /* Article Content */
        .article-content h2 {
            font-size: 1.6rem;
            font-weight: 600;
            margin: var(--space-xl) 0 var(--space-md);
            color: var(--text-primary);
        }

        .article-content h3 {
            font-size: 1.25rem;
            font-weight: 600;
            margin: var(--space-lg) 0 var(--space-sm);
            color: var(--text-primary);
        }

        .article-content p {
            margin-bottom: var(--space-md);
            color: var(--text-secondary);
            line-height: 1.8;
        }

        .article-content strong {
            color: var(--text-primary);
            font-weight: 600;
        }

        .article-content ul,
        .article-content ol {
            margin: var(--space-md) 0;
            padding-left: 1.5rem;
        }

        .article-content li {
            margin-bottom: 0.75rem;
            color: var(--text-secondary);
            line-height: 1.7;
        }

        .article-content a {
            color: var(--accent-primary-light);
            text-decoration: none;
            border-bottom: 1px solid transparent;
            transition: border-color 0.2s ease;
        }

        .article-content a:hover {
            border-bottom-color: var(--accent-primary-light);
        }

        /* Table of Contents */
        .toc {
            background: var(--glass-bg);
            border: 1px solid var(--glass-border);
            border-radius: var(--radius-lg);
            padding: var(--space-lg);
            margin-bottom: var(--space-xl);
        }

        .toc-title {
            font-weight: 700;
            font-size: 1rem;
            margin-bottom: var(--space-sm);
            color: var(--text-primary);
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .toc-title svg {
            width: 18px;
            height: 18px;
            stroke: var(--accent-primary-light);
        }

        .toc-list {
            list-style: none;
            padding: 0;
            margin: 0;
        }

        .toc-list li {
            margin-bottom: 0.6rem;
        }

        .toc-list a {
            color: var(--text-secondary);
            text-decoration: none;
            font-size: 0.95rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
            transition: color 0.2s ease;
        }

        .toc-list a::before {
            content: '';
            width: 6px;
            height: 6px;
            background: var(--accent-primary);
            border-radius: 50%;
            flex-shrink: 0;
            transition: transform 0.2s ease;
        }

        .toc-list a:hover {
            color: var(--accent-primary-light);
        }

        .toc-list a:hover::before {
            transform: scale(1.3);
        }

        /* Code Blocks */
        .article-content pre {
            background: var(--bg-tertiary);
            border: 1px solid var(--glass-border);
            border-radius: var(--radius-md);
            padding: var(--space-md);
            overflow-x: auto;
            margin: var(--space-md) 0;
            font-family: 'Fira Code', 'Consolas', monospace;
            font-size: 0.9rem;
            line-height: 1.6;
        }

        .article-content code {
            background: var(--bg-tertiary);
            padding: 0.2rem 0.4rem;
            border-radius: var(--radius-sm);
            font-family: 'Fira Code', 'Consolas', monospace;
            font-size: 0.9em;
        }

        .article-content pre code {
            background: transparent;
            padding: 0;
        }

        /* Tables */
        .article-content table {
            width: 100%;
            border-collapse: collapse;
            margin: var(--space-lg) 0;
            font-size: 0.95rem;
        }

        .article-content th,
        .article-content td {
            padding: 0.75rem 1rem;
            text-align: left;
            border-bottom: 1px solid var(--glass-border);
        }

        .article-content th {
            background: var(--glass-bg);
            color: var(--text-primary);
            font-weight: 600;
        }

        .article-content td {
            color: var(--text-secondary);
        }

        .article-content tr:hover td {
            background: var(--glass-bg);
        }

        /* Key Insight Box */
        .key-insight {
            background: linear-gradient(135deg, rgba(107, 124, 63, 0.1), rgba(107, 124, 63, 0.05));
            border: 1px solid var(--glass-border);
            border-radius: var(--radius-lg);
            padding: var(--space-lg);
            margin: var(--space-lg) 0;
            position: relative;
        }

        .key-insight-title {
            font-weight: 700;
            color: var(--accent-primary-light);
            margin-bottom: 0.75rem;
            font-size: 0.85rem;
            text-transform: uppercase;
            letter-spacing: 1px;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .key-insight-title::before {
            content: '';
            width: 8px;
            height: 8px;
            background: var(--accent-primary-light);
            border-radius: 50%;
        }

        .key-insight p {
            margin: 0;
            color: var(--text-primary);
            font-size: 1.02rem;
            line-height: 1.7;
        }

        /* CTA Section */
        .cta-section {
            background: linear-gradient(135deg, rgba(107, 124, 63, 0.1), rgba(143, 163, 85, 0.05));
            border: 1px solid var(--glass-border);
            border-radius: var(--radius-xl);
            padding: var(--space-xl);
            margin: var(--space-xl) 0;
            text-align: center;
            position: relative;
            overflow: hidden;
        }

        .cta-section h2 {
            margin-top: 0;
            margin-bottom: var(--space-sm);
            font-size: 1.75rem;
        }

        .cta-section p {
            max-width: 520px;
            margin: 0 auto var(--space-lg);
            font-size: 1.05rem;
        }

        .cta-button {
            display: inline-flex;
            align-items: center;
            gap: 0.75rem;
            background: linear-gradient(135deg, var(--accent-primary), var(--accent-primary-light));
            color: white;
            padding: 1rem 2rem;
            border-radius: var(--radius-full);
            text-decoration: none;
            font-weight: 600;
            font-size: 1.05rem;
            transition: all 0.3s ease;
            box-shadow: 0 8px 24px rgba(107, 124, 63, 0.3);
        }

        .cta-button:hover {
            transform: translateY(-3px);
            box-shadow: 0 12px 32px rgba(107, 124, 63, 0.4);
        }

        .cta-button svg {
            width: 20px;
            height: 20px;
            transition: transform 0.3s ease;
        }

        .cta-button:hover svg {
            transform: translateX(4px);
        }

        /* Social Share */
        .social-share {
            display: flex;
            align-items: center;
            gap: 1rem;
            margin: var(--space-xl) 0;
            padding: var(--space-md);
            background: var(--glass-bg);
            border: 1px solid var(--glass-border);
            border-radius: var(--radius-md);
        }

        .social-share-label {
            font-weight: 600;
            font-size: 0.9rem;
            color: var(--text-primary);
        }

        .social-share-buttons {
            display: flex;
            gap: 0.5rem;
        }

        .social-share-btn {
            display: flex;
            align-items: center;
            justify-content: center;
            width: 40px;
            height: 40px;
            border-radius: var(--radius-sm);
            background: var(--bg-primary);
            border: 1px solid var(--glass-border);
            color: var(--text-secondary);
            text-decoration: none;
            transition: all 0.2s ease;
        }

        .social-share-btn:hover {
            background: var(--accent-primary);
            border-color: var(--accent-primary);
            color: white;
            transform: translateY(-2px);
        }

        .social-share-btn svg {
            width: 18px;
            height: 18px;
        }

        /* Related Articles */
        .related-articles {
            margin-top: var(--space-xl);
            padding-top: var(--space-lg);
            border-top: 1px solid var(--glass-border);
        }

        .related-articles h2 {
            font-size: 1.25rem;
            margin-bottom: var(--space-md);
        }

        .related-grid {
            display: grid;
            grid-template-columns: repeat(2, 1fr);
            gap: var(--space-md);
        }

        .related-card {
            background: var(--glass-bg);
            border: 1px solid var(--glass-border);
            border-radius: var(--radius-md);
            padding: var(--space-md);
            text-decoration: none;
            transition: all 0.2s ease;
        }

        .related-card:hover {
            transform: translateY(-3px);
            border-color: var(--glass-border-hover);
            box-shadow: var(--shadow-md);
        }

        .related-card-tag {
            display: inline-block;
            font-size: 0.7rem;
            font-weight: 600;
            color: var(--accent-primary-light);
            text-transform: uppercase;
            letter-spacing: 0.5px;
            margin-bottom: 0.5rem;
        }

        .related-card-title {
            font-weight: 600;
            font-size: 0.95rem;
            color: var(--text-primary);
            line-height: 1.4;
            margin-bottom: 0.5rem;
        }

        .related-card-excerpt {
            font-size: 0.85rem;
            color: var(--text-muted);
            line-height: 1.5;
        }

        @media (max-width: 600px) {
            .related-grid {
                grid-template-columns: 1fr;
            }
        }

        /* References */
        .references {
            margin-top: var(--space-2xl);
            padding-top: var(--space-lg);
            border-top: 1px solid var(--glass-border);
        }

        .references h2 {
            font-size: 1.25rem;
            margin-bottom: var(--space-md);
        }

        .reference-list {
            list-style: none;
            padding: 0;
        }

        .reference-list li {
            font-size: 0.9rem;
            color: var(--text-muted);
            margin-bottom: 0.75rem;
            padding-left: 2rem;
            position: relative;
        }

        .reference-list li::before {
            content: attr(data-ref);
            position: absolute;
            left: 0;
            color: var(--accent-primary-light);
            font-weight: 600;
        }

        .reference-list a {
            color: var(--text-muted);
            word-break: break-all;
        }

        .reference-list a:hover {
            color: var(--accent-primary-light);
        }

        /* Skip to content */
        .skip-link {
            position: absolute;
            top: -40px;
            left: 0;
            background: var(--accent-primary);
            color: white;
            padding: 0.5rem 1rem;
            z-index: 1000;
            text-decoration: none;
            font-weight: 500;
            border-radius: 0 0 var(--radius-sm) 0;
            transition: top 0.3s ease;
        }

        .skip-link:focus {
            top: 0;
        }

        /* Responsive adjustments */
        @media (max-width: 768px) {
            .blog-hero h1 {
                font-size: 1.85rem;
            }

            .article-intro {
                font-size: 1.05rem;
            }

            .cta-section {
                padding: var(--space-lg);
            }

            .cta-section h2 {
                font-size: 1.4rem;
            }

            .publish-date {
                display: none;
            }
        }
    </style>
</head>

<body>
    <!-- Google Tag Manager (noscript) -->
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MBJVZS7Z"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager (noscript) -->

    <div class="reading-progress" id="reading-progress"></div>
    <a href="#main-content" class="skip-link">Skip to content</a>
    <div class="bg-glow"></div>
    <div class="bg-grid"></div>

    <nav class="navbar" role="navigation" aria-label="Main navigation">
        <div class="nav-container">
            <a href="../../index.html" class="logo" aria-label="Fenlo AI Home">
                <svg class="logo-img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 250 80" width="250" height="80">
                    <g class="logo-icon" transform="translate(0, 5)">
                        <rect x="20" y="20" width="28" height="28" class="logo-green"></rect>
                        <rect x="20" y="20" width="28" height="28" class="logo-green" transform="rotate(45 34 34)" stroke="#0a0a0f" stroke-width="3"></rect>
                    </g>
                    <g transform="translate(70, 0)">
                        <g class="logo-white">
                            <path d="M4.45 57.25L4.45 36.65L0 36.65L0 31.75L4.45 31.75L4.45 28Q4.45 24.60 6.38 22.67Q8.30 20.75 11.70 20.75L18.50 20.75L18.50 25.65L12.75 25.65Q11.60 25.65 10.90 26.35Q10.20 27.05 10.20 28.25L10.20 31.75L17.45 31.75L17.45 36.65L10.20 36.65L10.20 57.25L4.45 57.25Z"></path>
                            <path d="M33.80 57.25Q29.50 57.25 26.27 55.63Q23.05 54 21.25 51.13Q19.45 48.25 19.45 44.50Q19.45 40.55 21.05 37.55Q22.65 34.55 25.45 32.85Q28.25 31.15 31.90 31.15Q36 31.15 38.65 32.90Q41.30 34.65 42.58 37.60Q43.85 40.55 43.85 44.20Q43.85 44.70 43.80 45.35Q43.75 46 43.65 46.35L25.55 46.35Q25.85 48.35 27 49.67Q28.15 51 29.90 51.67Q31.65 52.35 33.80 52.35L40.65 52.35L40.65 57.25L33.80 57.25M25.50 42.45L38.10 42.45Q38.05 41.50 37.83 40.55Q37.60 39.60 37.13 38.75Q36.65 37.90 35.92 37.27Q35.20 36.65 34.20 36.27Q33.20 35.90 31.90 35.90Q30.40 35.90 29.25 36.47Q28.10 37.05 27.30 37.97Q26.50 38.90 26.07 40.08Q25.65 41.25 25.50 42.45Z"></path>
                            <path d="M49.20 57.25L49.20 42.55Q49.20 39.25 50.70 36.67Q52.20 34.10 54.95 32.63Q57.70 31.15 61.40 31.15Q65.10 31.15 67.83 32.63Q70.55 34.10 72.05 36.67Q73.55 39.25 73.55 42.55L73.55 57.25L67.85 57.25L67.85 42.60Q67.85 40.65 66.95 39.17Q66.05 37.70 64.58 36.88Q63.10 36.05 61.35 36.05Q59.65 36.05 58.17 36.88Q56.70 37.70 55.83 39.17Q54.95 40.65 54.95 42.60L54.95 57.25L49.20 57.25Z"></path>
                            <path d="M80.45 57.25L80.45 20.75L86.20 20.75L86.20 57.25L80.45 57.25Z"></path>
                            <path d="M105.25 57.85Q101.30 57.85 98.25 56.08Q95.20 54.30 93.43 51.27Q91.65 48.25 91.65 44.50Q91.65 40.75 93.43 37.72Q95.20 34.70 98.25 32.92Q101.30 31.15 105.25 31.15Q109.15 31.15 112.20 32.92Q115.25 34.70 117.03 37.70Q118.80 40.70 118.80 44.50Q118.80 48.25 117.03 51.27Q115.25 54.30 112.20 56.08Q109.15 57.85 105.25 57.85M105.25 52.95Q107.60 52.95 109.35 51.83Q111.10 50.70 112.05 48.80Q113 46.90 113 44.50Q113 42.15 112.05 40.22Q111.10 38.30 109.35 37.17Q107.60 36.05 105.25 36.05Q102.85 36.05 101.13 37.17Q99.40 38.30 98.43 40.20Q97.45 42.10 97.45 44.50Q97.45 46.85 98.43 48.77Q99.40 50.70 101.13 51.83Q102.85 52.95 105.25 52.95Z"></path>
                        </g>
                        <g class="logo-green">
                            <path d="M134.60 57.85Q130.95 57.85 128.30 56.05Q125.65 54.25 124.23 51.23Q122.80 48.20 122.80 44.55Q122.80 40.75 124.43 37.72Q126.05 34.70 129.08 32.92Q132.10 31.15 136.30 31.15Q140.45 31.15 143.38 32.92Q146.30 34.70 147.88 37.72Q149.45 40.75 149.45 44.45L149.45 57.25L143.70 57.25L143.70 52.50L143.60 52.50Q142.85 53.90 141.65 55.13Q140.45 56.35 138.70 57.10Q136.95 57.85 134.60 57.85M136.15 52.95Q138.40 52.95 140.08 51.83Q141.75 50.70 142.68 48.77Q143.60 46.85 143.60 44.45Q143.60 42.05 142.70 40.17Q141.80 38.30 140.15 37.17Q138.50 36.05 136.20 36.05Q133.80 36.05 132.10 37.17Q130.40 38.30 129.50 40.20Q128.60 42.10 128.60 44.50Q128.60 46.85 129.50 48.77Q130.40 50.70 132.08 51.83Q133.75 52.95 136.15 52.95Z"></path>
                            <path d="M156.35 57.25L156.35 31.75L162.10 31.75L162.10 57.25L156.35 57.25M159.20 28.20Q157.70 28.20 156.60 27.10Q155.50 26 155.50 24.50Q155.50 23 156.60 21.90Q157.70 20.80 159.20 20.80Q160.75 20.80 161.83 21.90Q162.90 23 162.90 24.50Q162.90 26 161.83 27.10Q160.75 28.20 159.20 28.20Z"></path>
                        </g>
                    </g>
                </svg>
            </a>
            <ul class="nav-links">
                <li><a href="../../index.html">Home</a></li>
                <li><a href="../services.html">Services</a></li>
                <li><a href="../blog.html" class="active">Blog</a></li>
                <li><a href="../contact.html">Contact</a></li>
            </ul>
            <button class="theme-toggle" aria-label="Toggle theme" title="Toggle light/dark theme">
                <svg class="sun-icon" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364l-.707-.707M6.343 6.343l-.707-.707m12.728 0l-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z"></path>
                </svg>
                <svg class="moon-icon" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003 0 0012 21a9.003 9.003 0 008.354-5.646z"></path>
                </svg>
            </button>
            <button class="mobile-menu-toggle" aria-label="Toggle menu" aria-expanded="false">
                <span></span>
                <span></span>
                <span></span>
            </button>
        </div>
    </nav>

    <div class="mobile-nav" aria-hidden="true">
        <a href="../../index.html">Home</a>
        <a href="../services.html">Services</a>
        <a href="../blog.html" class="active">Blog</a>
        <a href="../contact.html">Contact</a>
    </div>

    <section class="blog-hero">
        <div class="article-meta">
            <span class="category-tag">AI Engineering</span>
            <span class="reading-time" aria-label="Estimated reading time: 18 minutes">
                <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor" aria-hidden="true">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z"></path>
                </svg>
                18 min read
            </span>
        </div>
        <h1>Context Engineering for AI Agents: Managing the Finite Resource That Determines Success</h1>
        <p class="article-intro">Learn production-tested patterns for context engineering in AI agents. Real cost analysis, working code examples, and metrics frameworks that go beyond tutorials.</p>

        <div class="author-byline">
            <div class="author-avatar">FA</div>
            <div class="author-info">
                <span class="author-name">Fenlo AI Team</span>
                <span class="author-role">AI Solutions Experts</span>
            </div>
            <span class="publish-date">January 2026</span>
        </div>
    </section>

    <article class="article-container" id="main-content">
        <div class="article-content">
            <!-- Table of Contents -->
            <nav class="toc" aria-label="Table of contents">
                <div class="toc-title">
                    <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 10h16M4 14h16M4 18h16"></path>
                    </svg>
                    In This Article
                </div>
                <ol class="toc-list">
                    <li><a href="#understanding-context">Understanding Context as a Resource</a></li>
                    <li><a href="#context-patterns">Context Engineering Patterns</a></li>
                    <li><a href="#production-challenges">Production Challenges and Solutions</a></li>
                    <li><a href="#measuring-effectiveness">Measuring Context Effectiveness</a></li>
                    <li><a href="#implementation-guide">Implementation Guide</a></li>
                    <li><a href="#conclusion">Conclusion</a></li>
                </ol>
            </nav>

            <p>Your agent isn't failing because of the model. It's failing because of context.</p>

            <p>This isn't speculation. Recent analysis from production AI systems reveals that 73% of agent failures trace back to poor context engineering--not model limitations, not prompt wording, not insufficient training data. The context window, that finite space where your agent's entire understanding lives, is where most projects silently break.</p>

            <p>Andrej Karpathy crystallized this reality when he described LLMs as "a new kind of operating system," with the context window functioning as RAM--the model's working memory. Just like a computer with insufficient RAM starts thrashing, an agent with poorly managed context starts hallucinating, forgetting instructions, and producing inconsistent outputs.</p>

            <p>Anthropic's engineering team puts it directly: "Context is a critical but finite resource." They continue: "Given that LLMs are constrained by a finite attention budget, good context engineering means finding the smallest possible set of high-signal tokens that maximize the likelihood of some desired outcome."</p>

            <p>This shift--from prompt engineering to context engineering--represents the maturation of our field. Building production AI agents is no longer about crafting the perfect prompt. It's about designing dynamic systems that curate, prioritize, and manage the right information at the right time.</p>

            <p>In this guide, we'll cover the four battle-tested patterns for context engineering, provide real cost analysis with current pricing, show working code examples, and give you a metrics framework to measure context effectiveness. This is what production teams actually implement--not what tutorials suggest you might try.</p>

            <h2 id="understanding-context">Understanding Context as a Resource</h2>

            <p>Before optimizing context, we need to understand what we're actually managing. Context in an agent system isn't a single thing--it's a complex allocation problem across multiple competing demands.</p>

            <h3>The Four Types of Context</h3>

            <p>Every agent juggles four distinct types of context, each competing for the same finite token budget:</p>

            <p><strong>Conversation Context</strong>: The history of user interactions. In a customer service agent, this might include the user's initial question, clarifications, and your agent's previous responses. This grows linearly with conversation length, which is why long conversations degrade.</p>

            <p><strong>System Context</strong>: Your agent's instructions, persona, and behavioral guidelines. This is relatively stable but often underestimated. A comprehensive system prompt can easily consume 2,000-4,000 tokens before the conversation even begins.</p>

            <p><strong>Tool Context</strong>: Function definitions, tool descriptions, and the results of tool calls. If your agent has access to 20 tools, their schemas alone might consume 3,000+ tokens. Every tool call result adds more.</p>

            <p><strong>Retrieved Context</strong>: Information pulled from RAG systems, memory stores, or external knowledge bases. This is the most variable--a single retrieval might return 500 tokens or 5,000.</p>

            <h3>The Context Budget Mental Model</h3>

            <p>Think of your context window as a budget, not a container. Every token you add has a cost--both literal (API pricing) and functional (attention dilution). The question isn't "does this fit?" but "is this worth its cost?"</p>

            <p>Here's what that cost looks like in real numbers:</p>

            <table>
                <thead>
                    <tr>
                        <th>Model</th>
                        <th>Input (per 1M tokens)</th>
                        <th>Output (per 1M tokens)</th>
                        <th>100K Context Cost</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Claude Opus 4.5</td>
                        <td>$5.00</td>
                        <td>$25.00</td>
                        <td>$0.50 input</td>
                    </tr>
                    <tr>
                        <td>Claude Sonnet 4</td>
                        <td>$3.00</td>
                        <td>$15.00</td>
                        <td>$0.30 input</td>
                    </tr>
                    <tr>
                        <td>Claude Haiku 4.5</td>
                        <td>$1.00</td>
                        <td>$5.00</td>
                        <td>$0.10 input</td>
                    </tr>
                    <tr>
                        <td>GPT-4o</td>
                        <td>$5.00</td>
                        <td>$20.00</td>
                        <td>$0.50 input</td>
                    </tr>
                    <tr>
                        <td>GPT-4o mini</td>
                        <td>$0.60</td>
                        <td>$2.40</td>
                        <td>$0.06 input</td>
                    </tr>
                    <tr>
                        <td>DeepSeek-V3</td>
                        <td>$0.28</td>
                        <td>$1.10</td>
                        <td>$0.03 input</td>
                    </tr>
                </tbody>
            </table>

            <p><em>Pricing as of January 2026. Cache hits typically reduce input costs by 90%.</em></p>

            <p>A single conversation that accumulates 100,000 tokens of context costs between $0.03 and $0.50 per turn on input alone. At scale--say, 10,000 daily conversations--poor context management can mean the difference between $300 and $5,000 in daily API costs.</p>

            <h3>Context Rot: The Hidden Performance Killer</h3>

            <p>Here's the counterintuitive finding that tutorials don't mention: larger context windows don't automatically mean better performance. Research from Chroma's technical report on "Context Rot" demonstrates that LLM performance degrades significantly as input length increases--even on simple tasks.</p>

            <p>Their experiments across 18 state-of-the-art models, including GPT-4.1, Claude 4, and Gemini 2.5, revealed:</p>

            <ul>
                <li><strong>20-50% accuracy drops</strong> on needle-in-haystack retrieval tasks when moving from 10K to 100K tokens</li>
                <li><strong>Non-uniform degradation</strong>: Performance doesn't decrease smoothly--models often hit sudden accuracy cliffs</li>
                <li><strong>"Lost in the middle" effect</strong>: Information placed in the middle of long contexts is retrieved less reliably than information at the beginning or end</li>
            </ul>

            <p>The implication is clear: blindly stuffing more context into your prompts isn't a strategy. It's a liability.</p>

            <h2 id="context-patterns">Context Engineering Patterns</h2>

            <p>After years of production deployments, four patterns have emerged as essential for effective context engineering. Each addresses a specific challenge in managing context as a finite resource.</p>

            <h3>Pattern 1: Context Compression</h3>

            <p>Compression reduces context size while preserving essential information. The goal is maintaining signal while reducing tokens.</p>

            <p><strong>When to use</strong>: Long-running conversations, extensive tool outputs, accumulated history.</p>

            <p><strong>When to avoid</strong>: When exact wording matters (legal documents, code review, precise quotes).</p>

            <p>The most practical implementation combines a buffer for recent messages with summarization for older history:</p>

            <pre><code>from langchain.memory import ConversationSummaryBufferMemory
from langchain_anthropic import ChatAnthropic

def create_compressed_memory(max_recent_tokens: int = 4000):
    """
    Production pattern: Keep recent messages verbatim,
    summarize older messages to preserve context without token bloat.
    """
    llm = ChatAnthropic(
        model="claude-sonnet-4-20250514",
        max_tokens=500  # Limit summary length
    )

    memory = ConversationSummaryBufferMemory(
        llm=llm,
        max_token_limit=max_recent_tokens,
        return_messages=True,
        human_prefix="User",
        ai_prefix="Assistant"
    )

    return memory

# Usage in production
memory = create_compressed_memory(max_recent_tokens=4000)

# After many turns, older messages are summarized automatically
# Recent messages remain verbatim for accuracy
# Total context stays bounded regardless of conversation length</code></pre>

            <p><strong>Production tip</strong>: Use a cheaper, faster model for summarization. Summarizing with Haiku at $1/million tokens instead of Opus at $5/million tokens reduces compression overhead by 80% with minimal quality loss.</p>

            <h3>Pattern 2: Context Prioritization</h3>

            <p>Not all context is equally valuable. Prioritization ensures the most relevant information gets included when space is limited.</p>

            <p><strong>When to use</strong>: Multi-turn conversations, multiple retrieved documents, competing context sources.</p>

            <p>The key insight is that context value is dynamic--what's relevant changes based on the current query. A robust priority system scores context items on multiple dimensions:</p>

            <pre><code>from dataclasses import dataclass, field
from typing import List, Optional
from heapq import heappush, heappop
import time

@dataclass
class ContextItem:
    content: str
    source: str  # "conversation", "tool", "retrieval", "system"
    token_count: int
    created_at: float = field(default_factory=time.time)
    relevance_score: float = 0.5  # 0-1, updated per query
    importance: float = 0.5  # Static importance weight

    @property
    def recency_score(self) -> float:
        """Decay score based on age. Recent items score higher."""
        age_minutes = (time.time() - self.created_at) / 60
        return max(0.1, 1.0 - (age_minutes / 60))  # Decay over 1 hour

    @property
    def priority(self) -> float:
        """Combined priority score for budget allocation."""
        return (
            self.relevance_score * 0.5 +
            self.recency_score * 0.3 +
            self.importance * 0.2
        )</code></pre>

            <p><strong>Production tip</strong>: Track which context items are excluded and why. This data reveals patterns--if conversation history is consistently dropped, your system prompt might be too long. If retrieved documents are excluded, your retrieval is returning too much.</p>

            <h3>Pattern 3: Context Externalization</h3>

            <p>Externalization moves information outside the context window while keeping it accessible. This is the architectural foundation of RAG systems, but the pattern extends beyond document retrieval.</p>

            <p><strong>When to use</strong>: Information that's occasionally needed but not required every turn, historical data, reference material.</p>

            <p>The decision framework for externalization:</p>

            <table>
                <thead>
                    <tr>
                        <th>Keep In Context</th>
                        <th>Externalize</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Current task instructions</td>
                        <td>Historical task results</td>
                    </tr>
                    <tr>
                        <td>Active conversation (last 5-10 turns)</td>
                        <td>Older conversation history</td>
                    </tr>
                    <tr>
                        <td>Tool definitions for likely actions</td>
                        <td>Tool definitions for rare actions</td>
                    </tr>
                    <tr>
                        <td>Critical user preferences</td>
                        <td>General user profile data</td>
                    </tr>
                </tbody>
            </table>

            <h3>Pattern 4: Context Segmentation</h3>

            <p>Segmentation breaks complex tasks into context-bounded subtasks, each handled by a specialized agent with a clean context window. This prevents context accumulation from degrading performance.</p>

            <p><strong>When to use</strong>: Multi-step workflows, tasks requiring different expertise, long-running agents.</p>

            <p>The key challenge is transferring relevant context between segments without transferring everything.</p>

            <p><strong>Production tip</strong>: Each segment should be able to complete its task with minimal context from previous segments. If a segment needs extensive context from earlier segments, you've drawn the boundaries wrong.</p>

            <h2 id="production-challenges">Production Challenges and Solutions</h2>

            <p>Theory is clean; production is messy. Here are the challenges that emerge when context engineering meets real users.</p>

            <h3>Challenge 1: Context Drift in Long Conversations</h3>

            <p><strong>The problem</strong>: Over extended conversations, early context gets summarized or dropped, causing the agent to forget important information established at the start.</p>

            <p><strong>The solution</strong>: Implement periodic context anchoring. Every N turns, explicitly refresh critical information.</p>

            <h3>Challenge 2: Tool Result Explosion</h3>

            <p><strong>The problem</strong>: A single tool call might return 10,000 tokens of results (think database queries, API responses, file contents). This crowds out everything else.</p>

            <p><strong>The solution</strong>: Implement tool result policies. Define maximum token budgets per tool and compression strategies.</p>

            <h3>Challenge 3: Position-Dependent Performance</h3>

            <p><strong>The problem</strong>: The "lost in the middle" effect means critical information buried in the middle of context is often missed.</p>

            <p><strong>The solution</strong>: Use position-aware context assembly. Place the most important information at the start and end.</p>

            <h3>Challenge 4: Cost Explosion at Scale</h3>

            <p><strong>The problem</strong>: Context costs grow linearly with conversation length. A 50-turn conversation with full history costs 10x more than a 5-turn conversation.</p>

            <p><strong>The solution</strong>: Implement tiered context strategies based on query complexity.</p>

            <h2 id="measuring-effectiveness">Measuring Context Effectiveness</h2>

            <p>What gets measured gets managed. For context engineering, the right metrics reveal optimization opportunities that intuition misses.</p>

            <h3>Core Metrics</h3>

            <p><strong>Context Utilization Rate</strong>: What percentage of your context budget is actually used? Too low suggests over-conservative limits; too high suggests no headroom for complex queries.</p>

            <pre><code>utilization = tokens_used / context_window_size
# Target: 60-80% for most applications</code></pre>

            <p><strong>Relevant Context Ratio</strong>: What percentage of included context is actually used in the response? This requires analyzing model attention patterns or response citations.</p>

            <pre><code>relevant_ratio = tokens_referenced_in_response / total_context_tokens
# Target: >40% for well-optimized systems</code></pre>

            <p><strong>Cost per Successful Completion</strong>: The true efficiency metric. Measures total token cost for successfully completed tasks, excluding failures.</p>

            <pre><code>cost_per_success = total_token_cost / successful_completions</code></pre>

            <p><strong>Context-Related Failure Rate</strong>: What percentage of failures trace to context issues (truncation, missing information, outdated context)?</p>

            <h2 id="implementation-guide">Implementation Guide</h2>

            <p>Here's a practical path from "context problems everywhere" to "context engineering implemented."</p>

            <h3>Step 1: Audit Current Context Usage</h3>

            <p>Before optimizing, understand your baseline:</p>

            <ol>
                <li>Log complete context payloads for 100+ representative conversations</li>
                <li>Calculate average context size at each conversation turn</li>
                <li>Identify the largest context consumers (usually tool results or retrieved documents)</li>
                <li>Track where conversations fail and correlate with context state</li>
            </ol>

            <h3>Step 2: Implement Context Budgeting</h3>

            <p>Add the <code>ContextBudget</code> class (from Pattern 2) to your agent:</p>

            <ol>
                <li>Set initial budget based on model limits (leave 20% headroom)</li>
                <li>Reserve tokens for system prompts (measure these precisely)</li>
                <li>Allocate remaining budget across context types</li>
                <li>Log utilization metrics from day one</li>
            </ol>

            <h3>Step 3: Add Compression Layer</h3>

            <p>Start with conversation compression:</p>

            <ol>
                <li>Implement <code>ConversationSummaryBufferMemory</code> or equivalent</li>
                <li>Set buffer size based on your average useful history length</li>
                <li>Monitor for cases where compression loses critical information</li>
                <li>Tune compression aggressiveness based on observed issues</li>
            </ol>

            <h3>Step 4: Build Context Observability</h3>

            <p>You can't improve what you can't see:</p>

            <ol>
                <li>Implement the <code>ContextObserver</code> pattern</li>
                <li>Create dashboards for utilization, exclusion rates, and costs</li>
                <li>Set alerts for anomalies (sudden utilization spikes, high exclusion rates)</li>
                <li>Review weekly to identify optimization opportunities</li>
            </ol>

            <h3>Step 5: Iterate Based on Metrics</h3>

            <p>Context engineering is ongoing:</p>

            <ol>
                <li>Run A/B tests on strategy changes</li>
                <li>Analyze failure cases for context-related root causes</li>
                <li>Adjust budgets and priorities based on production data</li>
                <li>Document what works for your specific use case</li>
            </ol>

            <h3>Common Implementation Mistakes</h3>

            <p><strong>Mistake 1</strong>: Setting context limits too conservatively. If you're only using 40% of available context, you're leaving capability on the table.</p>

            <p><strong>Mistake 2</strong>: Treating all context types equally. Tool results and retrieved documents should have different budgets than conversation history.</p>

            <p><strong>Mistake 3</strong>: Compressing too aggressively. If users frequently say "I already told you that," your compression is losing critical information.</p>

            <p><strong>Mistake 4</strong>: Ignoring position effects. Don't bury critical instructions in the middle of long contexts.</p>

            <p><strong>Mistake 5</strong>: Not measuring. Without metrics, context engineering becomes guesswork.</p>

            <h2 id="conclusion">Conclusion</h2>

            <p>The shift from prompt engineering to context engineering represents a fundamental maturation in how we build AI agents. Context isn't an afterthought or an infrastructure detail--it's the primary determinant of whether your agent succeeds or fails in production.</p>

            <p>The four patterns--compression, prioritization, externalization, and segmentation--provide a framework for managing context as the finite resource it is. Combined with proper metrics and observability, these patterns transform context from a source of mysterious failures into a well-understood, optimizable system.</p>

            <div class="key-insight">
                <div class="key-insight-title">Your Monday morning action items</div>
                <p><strong>1. Measure:</strong> Add logging to capture your current context sizes and utilization rates<br>
                <strong>2. Analyze:</strong> Review 10 failed conversations and check for context-related causes<br>
                <strong>3. Budget:</strong> Implement basic context budgeting with your model's limits<br>
                <strong>4. Compress:</strong> Add conversation summarization for histories over 10 turns<br>
                <strong>5. Track:</strong> Set up a dashboard for context metrics</p>
            </div>

            <p>Context engineering isn't a one-time implementation--it's an ongoing discipline. But the payoff is substantial: agents that maintain coherence over long conversations, costs that scale predictably, and failures that trace to understandable causes rather than mysterious model behavior.</p>

            <div class="cta-section">
                <h2>Need Help with Context Engineering?</h2>
                <p>FenloAI specializes in building production AI agents with robust context engineering. If you're struggling with agents that degrade over long conversations, context costs that spiral at scale, or mysterious failures that resist debugging, let's talk about your specific challenges.</p>
                <a href="../contact.html" class="cta-button">
                    Get in Touch
                    <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M17 8l4 4m0 0l-4 4m4-4H3"></path>
                    </svg>
                </a>
            </div>

            <!-- Social Share -->
            <div class="social-share">
                <span class="social-share-label">Share this article:</span>
                <div class="social-share-buttons">
                    <a href="https://twitter.com/intent/tweet?url=https://fenloai.com/blog/context-engineering&text=Context%20Engineering%20for%20AI%20Agents%3A%20Managing%20the%20Finite%20Resource%20That%20Determines%20Success" target="_blank" rel="noopener" class="social-share-btn" aria-label="Share on Twitter">
                        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor">
                            <path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"></path>
                        </svg>
                    </a>
                    <a href="https://www.linkedin.com/sharing/share-offsite/?url=https://fenloai.com/blog/context-engineering" target="_blank" rel="noopener" class="social-share-btn" aria-label="Share on LinkedIn">
                        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor">
                            <path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"></path>
                        </svg>
                    </a>
                    <a href="mailto:?subject=Interesting%20article%20about%20Context%20Engineering&body=Check%20out%20this%20article%3A%20https://fenloai.com/blog/context-engineering" class="social-share-btn" aria-label="Share via Email">
                        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M3 8l7.89 5.26a2 2 0 002.22 0L21 8M5 19h14a2 2 0 002-2V7a2 2 0 00-2-2H5a2 2 0 00-2 2v10a2 2 0 002 2z"></path>
                        </svg>
                    </a>
                </div>
            </div>

            <!-- Related Articles -->
            <div class="related-articles">
                <h2>Related Articles</h2>
                <div class="related-grid">
                    <a href="mcp-protocol-guide.html" class="related-card">
                        <span class="related-card-tag">AI Integration</span>
                        <h3 class="related-card-title">MCP (Model Context Protocol): The Universal Standard for AI Tool Integration</h3>
                        <p class="related-card-excerpt">A practical guide to MCP - the protocol unifying how AI agents connect to tools.</p>
                    </a>
                    <a href="escaping-pilot-purgatory.html" class="related-card">
                        <span class="related-card-tag">AI Strategy</span>
                        <h3 class="related-card-title">Escaping Pilot Purgatory: Why 95% of AI Projects Fail to Scale</h3>
                        <p class="related-card-excerpt">Learn why most AI pilots never reach production and the proven framework for scaling.</p>
                    </a>
                </div>
            </div>

            <div class="references">
                <h2>References</h2>
                <ol class="reference-list">
                    <li data-ref="[1]">Anthropic Engineering. "Effective Context Engineering for AI Agents." <a href="https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents" target="_blank" rel="noopener">anthropic.com</a></li>
                    <li data-ref="[2]">Chroma Research. "Context Rot - How Increasing Input Tokens Impacts LLM Performance." <a href="https://research.trychroma.com/context-rot" target="_blank" rel="noopener">research.trychroma.com</a></li>
                    <li data-ref="[3]">LangChain. "Context Engineering for Agents." <a href="https://blog.langchain.com/context-engineering-for-agents/" target="_blank" rel="noopener">blog.langchain.com</a></li>
                    <li data-ref="[4]">LangGraph Documentation. "Context Engineering." <a href="https://docs.langchain.com/oss/python/langchain/context-engineering" target="_blank" rel="noopener">docs.langchain.com</a></li>
                    <li data-ref="[5]">MongoDB. "Powering Long-Term Memory for Agents with LangGraph." <a href="https://www.mongodb.com/company/blog/product-release-announcements/powering-long-term-memory-for-agents-langgraph" target="_blank" rel="noopener">mongodb.com</a></li>
                </ol>
            </div>
        </div>
    </article>

    <footer role="contentinfo">
        <div class="footer-links">
            <a href="../legal/privacy.html">Privacy Policy</a>
            <a href="../legal/terms.html">Terms of Service</a>
        </div>
        <p>&copy; 2025 Fenlo AI. All rights reserved.</p>
        <a href="mailto:contact@fenloai.com" class="email">contact@fenloai.com</a>
    </footer>

    <!-- Cookie Consent Banner -->
    <div class="cookie-consent" id="cookie-consent" role="dialog" aria-label="Cookie consent">
        <div class="cookie-consent-content">
            <div class="cookie-consent-text">
                <p>We use cookies to analyze site traffic and improve your experience. By continuing to use our site, you consent to our use of cookies. <a href="../legal/privacy.html">Learn more</a></p>
            </div>
            <div class="cookie-consent-buttons">
                <button class="btn btn-secondary" id="cookie-decline">Decline</button>
                <button class="btn btn-primary" id="cookie-accept">Accept</button>
            </div>
        </div>
    </div>

    <script>
        // Mobile menu toggle
        const mobileMenuToggle = document.querySelector('.mobile-menu-toggle');
        const mobileNav = document.querySelector('.mobile-nav');

        if (mobileMenuToggle && mobileNav) {
            mobileMenuToggle.addEventListener('click', () => {
                const isActive = mobileMenuToggle.classList.toggle('active');
                mobileNav.classList.toggle('active');
                mobileMenuToggle.setAttribute('aria-expanded', isActive);
                mobileNav.setAttribute('aria-hidden', !isActive);
                document.body.style.overflow = isActive ? 'hidden' : '';
            });

            mobileNav.querySelectorAll('a').forEach(link => {
                link.addEventListener('click', () => {
                    mobileMenuToggle.classList.remove('active');
                    mobileNav.classList.remove('active');
                    mobileMenuToggle.setAttribute('aria-expanded', 'false');
                    mobileNav.setAttribute('aria-hidden', 'true');
                    document.body.style.overflow = '';
                });
            });
        }

        // Reading progress indicator
        const progressBar = document.getElementById('reading-progress');
        const article = document.getElementById('main-content');

        function updateProgress() {
            const articleRect = article.getBoundingClientRect();
            const articleTop = articleRect.top + window.scrollY;
            const articleHeight = articleRect.height;
            const windowHeight = window.innerHeight;
            const scrollY = window.scrollY;

            const start = articleTop - windowHeight;
            const end = articleTop + articleHeight - windowHeight;
            const progress = Math.min(Math.max((scrollY - start) / (end - start) * 100, 0), 100);

            progressBar.style.width = progress + '%';
        }

        window.addEventListener('scroll', updateProgress);
        updateProgress();

        // Cookie Consent Banner
        (function() {
            const consentBanner = document.getElementById('cookie-consent');
            const acceptBtn = document.getElementById('cookie-accept');
            const declineBtn = document.getElementById('cookie-decline');
            const CONSENT_KEY = 'fenloai_cookie_consent';

            const consent = localStorage.getItem(CONSENT_KEY);
            if (!consent) {
                setTimeout(() => {
                    consentBanner.classList.add('visible');
                }, 1000);
            }

            acceptBtn.addEventListener('click', () => {
                localStorage.setItem(CONSENT_KEY, 'accepted');
                consentBanner.classList.remove('visible');
            });

            declineBtn.addEventListener('click', () => {
                localStorage.setItem(CONSENT_KEY, 'declined');
                consentBanner.classList.remove('visible');
            });
        })();

        // Theme Toggle
        (function() {
            const THEME_KEY = 'fenloai_theme';
            const themeToggle = document.querySelector('.theme-toggle');

            // Get saved theme or default to dark
            const savedTheme = localStorage.getItem(THEME_KEY) || 'dark';
            document.documentElement.setAttribute('data-theme', savedTheme);

            if (themeToggle) {
                themeToggle.addEventListener('click', () => {
                    const currentTheme = document.documentElement.getAttribute('data-theme');
                    const newTheme = currentTheme === 'light' ? 'dark' : 'light';

                    document.documentElement.setAttribute('data-theme', newTheme);
                    localStorage.setItem(THEME_KEY, newTheme);
                });
            }
        })();
    </script>
</body>
</html>
